# DB-LSH N-Dimensional (V3) con R*-Tree 10D

ImplementaciÃ³n de **DB-LSH** (Database-friendly Locality-Sensitive Hashing) siguiendo el paper original, con extensiones para **N dimensiones** y proyecciÃ³n a **K=10 dimensiones**. Utiliza **window queries dinÃ¡micas** sobre un R*-tree 10D en lugar de buckets estÃ¡ticos, permitiendo bÃºsquedas aproximadas de vecinos mÃ¡s cercanos (c-ANN) eficientes en espacios de alta dimensionalidad.

## ğŸ“‹ Â¿QuÃ© es DB-LSH?

**DB-LSH** es una variante de LSH diseÃ±ada para integrarse con estructuras de indexaciÃ³n espacial existentes (como R*-tree) en lugar de usar tablas hash tradicionales.

### Diferencias clave con LSH clÃ¡sico:

| CaracterÃ­stica | LSH clÃ¡sico | DB-LSH (este proyecto) |
|----------------|-------------|------------------------|
| **Almacenamiento** | Buckets hash estÃ¡ticos | R*-tree 10D dinÃ¡mico |
| **BÃºsqueda** | Lookup directo en bucket | Window query 10D expansiva |
| **Colisiones** | Todos los puntos en bucket | Ventana `W(G(q), wâ‚€Â·r)` en 10D |
| **ExpansiÃ³n** | Probar mÃºltiples tablas L | Expandir radio `r â† cÂ·r` |
| **IndexaciÃ³n** | Hash tables | Ãndice espacial R*-tree 10D |
| **ProyecciÃ³n** | Variable | N-D â†’ 10D fijo |

### Ventajas de DB-LSH:

âœ… **Sin buckets fijos**: No desperdicia memoria en buckets vacÃ­os  
âœ… **Consultas dinÃ¡micas**: Ajusta la ventana segÃºn necesidad (r expansivo)  
âœ… **IntegraciÃ³n DB**: Se integra con Ã­ndices espaciales existentes  
âœ… **Escalable**: Funciona bien con datasets grandes

## ğŸ¯ Algoritmos del paper implementados

Este proyecto implementa fielmente los **Algorithm 1** y **Algorithm 2** del paper DB-LSH:

### **Algorithm 1: (r,c)-NN Query**

Busca un punto `o` tal que `||q,o|| â‰¤ cÂ·r` (vecino c-aproximado dentro de radio r):

```
Input: q (query point), r (radio), c (approximation ratio), t (parÃ¡metro)
Output: punto o Ã³ âˆ…

cnt â† 0
for i = 1 to L do:
    Compute G_i(q)  // proyecciÃ³n hash del query
    while a point o âˆˆ W(G_i(q), wâ‚€Â·r) is found do:
        cnt â† cnt + 1
        if cnt = 2tL + 1 OR ||q,o|| â‰¤ cÂ·r then:
            return o
return âˆ…
```

**Idea clave**: Usa **window query** `W(G(q), wâ‚€Â·r)` en el espacio proyectado para encontrar candidatos.

### **Algorithm 2: c-ANN Query** 

Encuentra un vecino c-aproximado expandiendo el radio dinÃ¡micamente:

```
Input: q (query point), c (approximation ratio)
Output: punto o

r â† 1
while TRUE do:
    o â† call (r,c)-NN
    if o â‰  âˆ… then:
        return o
    else:
        r â† cÂ·r  // expandir radio
```

**Idea clave**: Si no encuentra vecinos con radio `r`, **expande a `r â† cÂ·r`** y repite.

## ğŸš€ CÃ³mo ejecutar

### Requisitos

- **C++17** o superior
- **Boost.Geometry** (para R*-tree)
- **Make**

### InstalaciÃ³n de dependencias

```bash
# Ubuntu/Debian
sudo apt-get install libboost-all-dev

# Arch Linux
sudo pacman -S boost

# macOS (con Homebrew)
brew install boost
```

### CompilaciÃ³n y ejecuciÃ³n

```bash
cd V_2

# Compilar
make

# Ejecutar
./bin/main

# O compilar y ejecutar directamente
make run

# Limpiar y recompilar
make clean && make
```

## ğŸ“‚ Estructura del proyecto

```
V_3/
â”œâ”€â”€ main.cpp           # ImplementaciÃ³n K=10 con referencias al paper
â”œâ”€â”€ R_star.h           # Interfaz del R*-tree 10D
â”œâ”€â”€ R_star.cpp         # ImplementaciÃ³n del R*-tree 10D
â”œâ”€â”€ Makefile           # Sistema de compilaciÃ³n
â”œâ”€â”€ README.md          # Este archivo
â”œâ”€â”€ bin/               # Ejecutables (generado)
â””â”€â”€ obj/               # Archivos objeto (generado)
```

## ğŸ” Ejemplos de uso

### Ejemplo 1: 20D â†’ 10D (reducciÃ³n real)

```cpp
vector<vector<double>> datos_20d;
for(int i = 0; i < 8; i++) {
    vector<double> punto(20);
    for(int j = 0; j < 20; j++) {
        punto[j] = (i + 1) * 0.5 + j * 0.1;
    }
    datos_20d.push_back(punto);
}

DBfsh indice_20d(20, 1, 1.5, 1, 42);  // dim=20, L=1, C=1.5, t=1
indice_20d.insertar(datos_20d);

vector<double> query_20d(20);
for(int j = 0; j < 20; j++) {
    query_20d[j] = 1.5 + j * 0.1;
}
vector<double> vecino = indice_20d.C_ANN(query_20d, 1.5);
```

### Ejemplo 2: 50D â†’ 10D

```cpp
vector<vector<double>> datos_50d;
mt19937 gen(123);
normal_distribution<double> dist(0.0, 1.0);

for(int i = 0; i < 12; i++) {
    vector<double> punto(50);
    for(int j = 0; j < 50; j++) {
        punto[j] = dist(gen) + i * 0.2;
    }
    datos_50d.push_back(punto);
}

DBfsh indice_50d(50, 1, 2.0, 1, 456);
indice_50d.insertar(datos_50d);

vector<double> query_50d = datos_50d[5];
vector<double> vecino = indice_50d.C_ANN(query_50d, 2.0);
```

### Ejemplo 3: 128D â†’ 10D (tipo SIFT)

```cpp
vector<vector<double>> datos_128d;
mt19937 gen(789);
uniform_real_distribution<double> dist(0.0, 255.0);

for(int i = 0; i < 15; i++) {
    vector<double> punto(128);
    for(int j = 0; j < 128; j++) {
        punto[j] = dist(gen);
    }
    datos_128d.push_back(punto);
}

DBfsh indice_128d(128, 1, 2.5, 1, 999);
indice_128d.insertar(datos_128d);

vector<double> query_128d = datos_128d[8];
vector<double> vecino = indice_128d.C_ANN(query_128d, 2.5);
```

### Salida esperada

```
DB-LSH inicializado:
  DimensiÃ³n original: 50D
  DimensiÃ³n proyectada: 10D (R*-tree 10D)
  Tablas hash: 1
  C = 2, w0 = 16, t = 1
  Semilla: 456

Insertando 12 puntos de 50D...
Proyecciones generadas (primeros 5):
  Punto[0] 50D -> Hash 10D: [0.0107, 0.8406, 0.7435, ...]
  Punto[1] 50D -> Hash 10D: [0.4698, -0.3523, 0.2097, ...]
  ...

c-ANN Query (Algorithm 2)
Query 50D: [1.449, 1.059, 0.037, ...]

--- (r,c)-NN Query ---
Hash G(q) = [-1.199, 1.113, -1.271, 0.005, 0.631, ...]

Tabla 1:
  Window W(G(q), w=16):
    [-9.199, 6.801] Ã— ... Ã— [-8.632, 7.368]
  Puntos encontrados en ventana: 12
  Punto 1: id=0           ğŸ‘ˆ Â¡Usa ID del R*-tree directamente!
    ||q, o|| = 12.536, cr = 2
  ...

RESULTADO:
  Vecino encontrado 50D (primeras 5 dims): [-1.329, 1.131, 0.631, ...]
  Distancia euclidiana: 13.825
```

## ğŸ§ª Funcionamiento detallado de los algoritmos

### **Algorithm 1: (r,c)-NN Query** (del paper)

**Objetivo**: Encontrar un punto `o` tal que `dist(q, o) â‰¤ cÂ·r`

**Pasos de implementaciÃ³n:**

1. **Proyectar query**: Calcular `G(q) = (hâ‚(q), hâ‚‚(q))` donde:
   ```cpp
   hâ‚(q) = aâ‚ Â· q = Î£(aâ‚[j] * q[j])
   hâ‚‚(q) = aâ‚‚ Â· q = Î£(aâ‚‚[j] * q[j])
   ```

2. **Definir ventana**: `W(G(q), wâ‚€Â·r) = [hâ‚(q) - w/2, hâ‚(q) + w/2] Ã— [hâ‚‚(q) - w/2, hâ‚‚(q) + w/2]`
   - Ancho: `w = wâ‚€ Â· r` donde `wâ‚€ = 4cÂ²`
   - Centrada en el hash del query

3. **Buscar candidatos**: Ejecutar window query en R*-tree:
   ```cpp
   resultados = indice.windowQuery(x_min, y_min, x_max, y_max);
   ```

4. **Verificar distancias**: Para cada candidato encontrado:
   ```cpp
   int id = res.second;              // ID del R*-tree
   punto_original = datos[id];       // Recuperar original
   dist = distanciaEuclidiana(query, punto_original);
   ```

5. **Condiciones de parada** (del paper):
   - **Ã‰xito**: Si `dist(q, o) â‰¤ cÂ·r` â†’ retornar `o`
   - **LÃ­mite**: Si `cnt = 2tL + 1` â†’ retornar `o` (evita bÃºsqueda infinita)
   - **Fallo**: Si no quedan candidatos â†’ retornar `âˆ…`

### **Algorithm 2: c-ANN Query** (del paper)

**Objetivo**: Encontrar vecino c-aproximado sin conocer la distancia de antemano

**Estrategia de expansiÃ³n dinÃ¡mica:**

```
IteraciÃ³n 1: r = 1    â†’ ventana pequeÃ±a
IteraciÃ³n 2: r = 1.5  â†’ ventana 1.5Ã— mÃ¡s grande (si C=1.5)
IteraciÃ³n 3: r = 2.25 â†’ ventana 2.25Ã— mÃ¡s grande
...
```

**Flujo completo:**

```
Query q = (6, 6) con c = 1.5

Iter 1: r=1.0, w=9.0  â†’ W(G(q), 9)   â†’ No encuentra â†’ expandir
Iter 2: r=1.5, w=13.5 â†’ W(G(q), 13.5) â†’ Encuentra punto a dist=1.41
        âœ“ 1.41 â‰¤ 1.5Â·1.5 = 2.25 â†’ RETORNAR punto
```

**Por quÃ© funciona** (garantÃ­a del paper):
- Si existe un punto a distancia `d`, eventualmente `r â‰¥ d/c`
- Entonces la ventana serÃ¡ suficientemente grande para encontrarlo
- La expansiÃ³n geomÃ©trica (`r â† cÂ·r`) garantiza convergencia logarÃ­tmica

## ğŸ“Š ParÃ¡metros del sistema

| ParÃ¡metro | DescripciÃ³n | Valor tÃ­pico |
|-----------|-------------|--------------||
| **D** | DimensiÃ³n original | 20, 50, 128, 700, ... |
| **K** | DimensiÃ³n proyectada (fijo) | **10** (para R*-tree 10D) |
| **L** | Tablas hash | 1 (â³ pendiente L>1) |
| **C** | Factor aproximaciÃ³n | 1.5 - 3.0 |
| **t** | ParÃ¡metro tolerancia | 1 |
| **wâ‚€** | Ancho ventana base | 4Â·CÂ² = 9.0 (C=1.5) |
| **seed** | Semilla aleatoria | Cualquier unsigned int |

## ğŸ”§ Detalles de implementaciÃ³n

### Clase DBfsh (V3)

```cpp
class DBfsh {
private:
    int D;                           // DimensiÃ³n original (20, 50, 128, 700, ...)
    int K;                           // DimensiÃ³n hash (siempre 10)
    int L;                           // Tablas hash (actualmente 1)
    double C, w0;                    // ParÃ¡metros LSH
    int t;                           // Tolerancia
    unsigned seed;                   // Semilla reproducible
    
    vector<vector<double>> a;        // Matriz KÃ—D de proyecciÃ³n (10Ã—D)
    vector<vector<double>> datos;    // Datos originales (Ã­ndice = id)
    RStarTreeIndex indice;           // R*-tree 10D
    
    void generarFuncionesHash();     // Genera 10 vectores N(0,1)
    array<double,10> funcionHash(const vector<double>& punto);
    
public:
    DBfsh(int dim, int L_, double C_, int t_, unsigned seed_ = 42);
    void insertar(const vector<vector<double>>& datos);
    vector<double> RC_NN(const vector<double>& query, double r, double c);
    vector<double> C_ANN(const vector<double>& query, double c);
};
```

### Flujo de proyecciÃ³n N â†’ 10D

```
Punto original (N dimensiones: 20D, 50D, 128D, 700D, ...)
         â†“
    hâ‚ = aâ‚ Â· p = Î£(aâ‚[j] * p[j])  â†’ escalar
    hâ‚‚ = aâ‚‚ Â· p = Î£(aâ‚‚[j] * p[j])  â†’ escalar
    ...
    hâ‚â‚€ = aâ‚â‚€ Â· p = Î£(aâ‚â‚€[j] * p[j]) â†’ escalar
         â†“
   Hash 10D: [hâ‚, hâ‚‚, ..., hâ‚â‚€]
         â†“
    Insertar en R*-tree 10D con ID
```

### **RelaciÃ³n con el paper DB-LSH**

Este proyecto sigue fielmente el paper con estas correspondencias:

| Concepto del paper | ImplementaciÃ³n en cÃ³digo |
|-------------------|--------------------------||
| `G_i(q)` | `funcionHash(query)` â†’ `[hâ‚, hâ‚‚, ..., hâ‚â‚€]` |
| `W(G_i(q), wâ‚€Â·r)` | `windowQuery(mins, maxs)` con arrays 10D |
| Buckets L | R*-tree Ãºnico (â³ pendiente L>1) |
| CondiciÃ³n `cnt = 2tL+1` | Contador de candidatos inspeccionados |
| VerificaciÃ³n `||q,o||` | `distanciaEuclidiana(query, punto_original)` |
| ExpansiÃ³n `r â† cr` | Loop en `C_ANN` multiplicando r |
| EcuaciÃ³n (8) ventana | `[h_k(q) - w/2, h_k(q) + w/2]` para k=1..10 |

### **Extensiones mÃ¡s allÃ¡ del paper**

âœ… **N-dimensional**: El paper usa dimensiÃ³n fija, aquÃ­ es configurable  
âœ… **K=10 proyecciones**: Mejor discriminaciÃ³n que K=2  
âœ… **Vectores aleatorios**: Generados con `N(0,1)` normalizado (reproducible)  
âœ… **OptimizaciÃ³n O(1)**: Mapeo IDâ†’datos (no mencionado en paper, mejora prÃ¡ctica)  
âœ… **Arrays para ventanas**: Interfaz limpia `windowQuery(mins, maxs)`  
âœ… **Comentarios del paper**: CÃ³digo anotado con Algorithm 1/2 lÃ­neas  
â³ **Multi-L pendiente**: L>1 tablas hash independientes (siguiente versiÃ³n)

```cpp
// OptimizaciÃ³n de implementaciÃ³n (no del paper)
void insertar(const vector<vector<double>>& datos_input) {
    datos = datos_input;  // Guardar originales separados
    
    for (size_t i = 0; i < datos.size(); i++) {
        auto hash = funcionHash(datos[i]);
        int id = static_cast<int>(i);        // ID = Ã­ndice
        indice.insertPrueba(id, hash);       // R*-tree guarda (hash, id)
    }
}

// En RC_NN (del paper, pero optimizado):
int id = res.second;                         // R*-tree da ID (O(1))
const vector<double>& punto = datos[id];     // Acceso directo (O(1))
// En lugar de bÃºsqueda lineal en hash_to_original (O(N))
```

## ğŸ¯ Mejoras futuras

### â³ **Pendiente prioritario (V4)**

- â¬œ **Multi-L (L>1)**: MÃºltiples tablas hash independientes segÃºn paper
  - Cada tabla con sus propias K funciones hash G_i
  - IteraciÃ³n sobre L Ã­ndices R*-tree separados
  - Mejora garantÃ­as probabilÃ­sticas del paper

- â¬œ **Carga desde CSV**: Lector robusto para datasets reales
  - Soporte para archivos grandes (60,000+ puntos, 700+ dimensiones)
  - Parsing eficiente con `fstream`
  - ValidaciÃ³n de datos y manejo de errores
  - Ejemplo: `datos = cargarCSV("dataset_700d.csv");`

###  (âœ… = implementado en V3)

- âœ… **a aleatorios**: N(0,1) normalizados con semilla fija
- âœ… **Separar datos**: Vector `datos` separado del Ã­ndice (O(1) acceso)
- âœ… **N-dimensional**: Soporta cualquier dimensiÃ³n de entrada
- âœ… **K=10 dimensiones**: Mejor discriminaciÃ³n que K=2
- âœ… **Arrays ventanas**: `windowQuery(mins, maxs)` limpio
- â¬œ **MÃ©tricas**: `recall@k`, `overall ratio`, #candidatos, tiempo


## ğŸ“ˆ Casos de uso

### Datasets tÃ­picos

| Dataset | Dimensiones | TamaÃ±o | Uso |
|---------|-------------|--------|-----|
| **Iris** | 4D | 150 | ClasificaciÃ³n |
| **MNIST** | 784D | 60,000 | DÃ­gitos |
| **SIFT** | 128D | 1M - 1B | ImÃ¡genes |
| **GloVe** | 50D - 300D | 400K | Word embeddings |
| **Deep1B** | 96D | 1B | Deep features |

### ConfiguraciÃ³n recomendada

```cpp
// Para SIFT (128D â†’ 10D)
DBfsh sift_index(128, 1, 2.5, 1, 42);

// Para GloVe-200 (200D â†’ 10D)
DBfsh glove_index(200, 1, 2.0, 1, 999);

// Para datasets 700D (alta dimensionalidad)
DBfsh high_dim_index(700, 1, 3.0, 1, 123);

// Para datos densos medianos
DBfsh medium_index(50, 1, 1.5, 1, 456);
```

## ğŸ“– Referencias y conceptos

### **Paper original DB-LSH**

Este proyecto implementa los conceptos de:
- **Dynamic window queries** en lugar de buckets hash estÃ¡ticos
- **ExpansiÃ³n adaptativa** del radio de bÃºsqueda (`r â† cÂ·r`)
- **CondiciÃ³n de parada dual**: distancia exacta Ã³ lÃ­mite de candidatos
- **IntegraciÃ³n con Ã­ndices espaciales** (R*-tree en lugar de hash tables)

### **Conceptos clave**

- **LSH (Locality-Sensitive Hashing)**: Proyecta puntos similares a hashes similares
  - Propiedad: Si `dist(p, q)` pequeÃ±a â†’ `Pr[h(p) = h(q)]` alta
  - Funciones: `h_i(p) = âŒŠ(a_i Â· p + b) / wâŒ‹` (en el paper clÃ¡sico)
  
- **DB-LSH**: Variante database-friendly
  - NO usa buckets fijos â†’ usa **window queries dinÃ¡micas**
  - NO requiere hash tables â†’ usa **Ã­ndices espaciales existentes**
  - Ajusta ventana segÃºn necesidad (expansiÃ³n `r`)

- **c-ANN**: c-Approximate Nearest Neighbor
  - Encuentra punto `o` tal que `dist(q, o) â‰¤ c Â· dist(q, NN)`
  - Donde `NN` es el vecino mÃ¡s cercano real
  - Trade-off: precisiÃ³n vs velocidad (c=1.5 â†’ acepta 50% error)

- **R*-tree**: Ãndice espacial multidimensional de Boost.Geometry
  - Organiza puntos en rectÃ¡ngulos MBR (Minimum Bounding Rectangle)
  - Window query: `O(log n + k)` donde k = resultados
  - Permite bÃºsquedas rectangulares eficientes

### **GarantÃ­as teÃ³ricas del paper**

1. **Probabilidad de Ã©xito**: Con alta probabilidad encuentra vecino c-aproximado
2. **Tiempo**: O(n^Ï log n) donde Ï < 1 depende de c
3. **Espacio**: O(n) para almacenar proyecciones + Ã­ndice
4. **AproximaciÃ³n**: Garantiza factor c (configurable)

## ğŸ¤ Contribuciones

Proyecto educativo para Estructuras de Datos Avanzadas. Sugerencias bienvenidas.

## ğŸ“„ Licencia

Proyecto acadÃ©mico - Universidad XYZ

---

**Autor**: Manuel J. Silva  
**VersiÃ³n**: 3.0 (K=10 dimensiones, preparado para L>1 y CSV)  
**Fecha**: Noviembre 2025  
**TecnologÃ­as**: C++17, Boost.Geometry R*-tree 10D, LSH, STL

**Estado actual:**
- âœ… ImplementaciÃ³n fiel al paper DB-LSH (Algorithm 1 y 2)
- âœ… Soporte N-dimensional â†’ 10D con K=10 funciones hash
- âœ… Window queries 10D con arrays
- â³ Pendiente: Multi-L (L>1) y carga CSV para datasets reales (700D+)
