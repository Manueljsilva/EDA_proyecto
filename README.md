# DB-LSH: ImplementaciÃ³n Fiel al Paper Original

**Locality-Sensitive Hashing with Query-based Dynamic Bucketing (ICDE 2022)**

## ğŸ“‹ Â¿QuÃ© es DB-LSH?

**DB-LSH** es una variante de LSH diseÃ±ada para integrarse con estructuras de indexaciÃ³n espacial existentes (como R*-tree) en lugar de usar tablas hash tradicionales.

---

## ğŸ“– DescripciÃ³n

Este proyecto implementa **fielmente el algoritmo DB-LSH** segÃºn el pseudocÃ³digo publicado en el paper ICDE 2022.

**DB-LSH** combina Locality-Sensitive Hashing con Ã­ndices espaciales R*-tree para bÃºsquedas de vecinos mÃ¡s cercanos aproximados (c-ANN) en alta dimensiÃ³n.

---

## ğŸ¯ CaracterÃ­sticas

- âœ… **ImplementaciÃ³n fiel al paper**: Algoritmos 1 y 2 exactos
- âœ… **Fashion-MNIST**: 60,000 imÃ¡genes 784D
- âœ… **ProyecciÃ³n LSH**: 784D â†’ K-D (configurable)
- âœ… **R*-tree espacial**: Ãndices multidimensionales con bulk-loading
- âœ… **MÃ©tricas del paper**: Recall (Eq. 12), Overall Ratio (Eq. 11)
- âœ… **AnÃ¡lisis comparativo**: Paper vs GitHub original
- âœ… **DocumentaciÃ³n completa**: Diferencias y mejoras identificadas

---

## ğŸš€ Inicio RÃ¡pido

### Requisitos

```bash
# Ubuntu/Debian
sudo apt-get install g++ make libboost-all-dev python3 python3-pip

# Python (visualizaciÃ³n)
pip3 install pandas matplotlib numpy
```

### CompilaciÃ³n y EjecuciÃ³n

```bash
# Compilar
make clean && make all

# Experimento k-NN (k=1,10,20,...,100)
make run-k

# Experimento varying n (Fig. 5, 6, 7 del paper)
make run-grafico
```

---

## ğŸ“Š Experimentos Disponibles

### 1. k-NN Benchmark (`main_k.cpp`)

EvalÃºa calidad de resultados para diferentes valores de k:

```bash
make run-k
```

**ConfiguraciÃ³n:**
- k âˆˆ {1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100}
- **ParÃ¡metros usados:**
  - `C = 1.01` (approximation ratio)
  - `t = 500` (parÃ¡metro de lÃ­mite de accesos)
  - `K = 68` (dimensiÃ³n proyectada para R*-tree)
  - `L = 18` (nÃºmero de tablas hash)
  - `n = 60,000` (tamaÃ±o del dataset)

**Salida:**
- `results/knn_results.csv`: Recall y Ratio por k

---

### 2. Varying n (`main_grafico.cpp`)

Replica experimentos del paper variando tamaÃ±o del dataset:

```bash
make run-grafico
```

**ConfiguraciÃ³n:**
- n âˆˆ {0.2, 0.4, 0.6, 0.8, 1.0} (proporciÃ³n del dataset)
- k = 50 vecinos
- 50 queries promediadas
- **ParÃ¡metros usados:**
  - `C = 1.5` (approximation ratio)
  - `t = 8000` (parÃ¡metro de lÃ­mite de accesos)
  - `K = 83` (dimensiÃ³n proyectada para R*-tree)
  - `L = 2` (nÃºmero de tablas hash)

**Salida:**
- `results/varying_n_results.csv`: n, recall, ratio, tiempo promedio

---




### Resultados Experimentales

#### Experimento k-NN (ConfiguraciÃ³n: C=1.01, t=500, K=68, L=18)

| k | Recall (%) | Overall Ratio |
|---|------------|---------------|
| 10 | ~3-5% | ~1.01x |
| 50 | ~2-4% | ~1.01x |
| 100 | ~1-3% | ~1.01x |

*Nota: Ejecutar `make run-k` para obtener resultados detallados*

#### Experimento Varying n (ConfiguraciÃ³n: C=1.5, t=8000, K=83, L=2, k=50)

| n (proporciÃ³n) | Dataset Size | Recall (%) | Ratio | Time (ms) |
|----------------|--------------|------------|-------|----------|
| 0.2 | 12,000 | ~35% | ~1.14x | ~0.9 |
| 0.6 | 36,000 | ~30% | ~1.16x | ~1.1 |
| 1.0 | 60,000 | ~25% | ~1.18x | ~1.2 |

*Nota: Ejecutar `make run-grafico` para obtener resultados detallados*

**Observaciones:**
- Configuraciones diferentes producen trade-offs distintos entre recall y eficiencia
- C mÃ¡s bajo (1.01) mejora ratio pero reduce recall
- C mÃ¡s alto (1.5) mejora recall pero aumenta ratio
- El recall disminuye con datasets mÃ¡s grandes (comportamiento esperado en LSH)



---

## ğŸ“‚ Estructura del Proyecto

```
EDA_proyecto/
â”œâ”€â”€ R_star2.h                    # ImplementaciÃ³n R*-tree con Boost.Geometry
â”œâ”€â”€ main_k.cpp                   # Experimento k-NN benchmark
â”œâ”€â”€ main_grafico.cpp             # Experimento varying n
â”œâ”€â”€ main.cpp                     # Testing sintÃ©tico
â”œâ”€â”€ Makefile                     # CompilaciÃ³n y ejecuciÃ³n
â”œâ”€â”€ fashion_mnist.csv            # Dataset Fashion-MNIST (60k imÃ¡genes)
â”œâ”€â”€ calculate_parameters.py      # Script para calcular parÃ¡metros Ã³ptimos
â”œâ”€â”€ pgm_to_png.py               # Utilidad de conversiÃ³n de imÃ¡genes
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ bin/                         # Ejecutables compilados
â”‚   â”œâ”€â”€ main
â”‚   â”œâ”€â”€ main_k
â”‚   â””â”€â”€ main_grafico
â”œâ”€â”€ obj/                         # Archivos objeto (.o)
â””â”€â”€ results/                     # Resultados experimentales
    â”œâ”€â”€ knn_results.csv         # Resultados k-NN benchmark
    â””â”€â”€ varying_n_results.csv   # Resultados varying n
```

---

## âš™ï¸ ConfiguraciÃ³n de ParÃ¡metros

### Modificar ParÃ¡metros (main_k.cpp, main_grafico.cpp)

Los parÃ¡metros se definen con `#define` al final de cada archivo:

```cpp
// main_k.cpp - Ejemplo configuraciÃ³n Ã³ptima encontrada
#define MAIN_C 1.01      // Approximation ratio
#define MAIN_t 500       // ParÃ¡metro t del paper
#define MAIN_K 68        // DimensiÃ³n proyectada (R*-tree)
#define MAIN_L 18        // NÃºmero de tablas hash

// main_grafico.cpp - Ejemplo configuraciÃ³n
#define MAIN_C 1.5
#define MAIN_t 8000
#define MAIN_K 83
#define MAIN_L 2
```

### ParÃ¡metros Fijos en Constructor

```cpp
const int D = 784;           // DimensiÃ³n Fashion-MNIST
const double R_MIN = 1.0;    // Radio mÃ­nimo inicial
const unsigned seed = 42;    // Reproducibilidad
```

### FÃ³rmulas del Paper

```cpp
// LÃ­mite de accesos (Algorithm 1)
T = 2 * t * L + 1

// Ancho de ventana inicial
wâ‚€ = R_min * 4 * CÂ²

// ExpansiÃ³n de radio (Algorithm 2)
r_new = r_old * C
```

---

## ğŸ¯ Algoritmos Implementados

### Algorithm 1: (r,c)-NN Query

```cpp
// Input: query q, radio r, approx ratio c, k neighbors, lÃ­mite T
vector<tuple<int, vector<double>, double>> RC_NN_K(q, r, c, k, T) {
    candidatos = [];
    cnt = 0;
    
    for (i = 0; i < L; i++) {  // Para cada tabla hash
        W = windowQuery(hash(q), wâ‚€Â·r);  // BÃºsqueda en R*-tree
        
        for (o in W) {
            cnt++;
            dist = ||q - o||;
            
            // PAPER: Filtro por distancia (lÃ­nea 10)
            if (dist <= cÂ·r) {
                candidatos.push_back({id, punto, dist});
            }
            
            if (cnt >= T || |candidatos| >= k) {
                return candidatos;
            }
        }
    }
    return candidatos;
}
```

### Algorithm 2: c-ANN Query

```cpp
// Input: query q, approx ratio c, k neighbors
vector<tuple<int, vector<double>, double>> C_ANN_K(q, c, k) {
    r = R_min;
    T = 2*t*L + 1;  // PAPER: LÃ­mite fijo
    acumulados = [];
    
    while (true) {  // PAPER: Sin lÃ­mite de rondas
        nuevos = RC_NN_K(q, r, c, k, T);
        acumular(nuevos);  // Evitar duplicados
        
        if (|acumulados| >= k) {
            return top_k(acumulados);  // Ordenar por distancia
        }
        
        r = r * c;  // Expandir radio
    }
}
```

**Nota:** Esta implementaciÃ³n sigue el pseudocÃ³digo exacto. Ver comentarios en cÃ³digo para diferencias con GitHub.

---

## ğŸ“ˆ MÃ©tricas Implementadas

### 1. Recall (EcuaciÃ³n 12)

$$\text{Recall} = \frac{|R \cap R^*|}{k}$$

- **R**: Conjunto de IDs devueltos por DB-LSH
- **R***: Conjunto de IDs de k vecinos reales (ground truth)
- **ImplementaciÃ³n**: IntersecciÃ³n de sets

```cpp
set<int> ids_dblsh = {IDs de resultado DB-LSH};
set<int> ids_reales = {IDs de ground truth};
recall = intersection(ids_dblsh, ids_reales).size() / k;
```

### 2. Overall Ratio (EcuaciÃ³n 11)

$$\text{Overall Ratio} = \frac{1}{k} \sum_{i=1}^{k} \frac{\text{dist}(q, o_i)}{\text{dist}(q, o_i^*)}$$

- Promedio de ratios individuales de distancias
- **Ideal**: 1.0 (exacto)
- **Aceptable**: â‰¤ c (approximation ratio)

```cpp
ratio = mean(dist_dblsh[i] / dist_real[i] for i in [0..k-1]);
```

### 3. Query Time

```cpp
auto start = high_resolution_clock::now();
vecinos = indice.C_ANN_K(query, C, k);
auto end = high_resolution_clock::now();
time_ms = duration_cast<microseconds>(end - start).count() / 1000.0;
```

---

## ğŸ”§ Detalles de ImplementaciÃ³n

### Clase Principal

```cpp
template <size_t K>  // K = dimensiÃ³n proyectada (R*-tree)
class DBLSH {
private:
    int D;                              // DimensiÃ³n original (784)
    int L;                              // NÃºmero de tablas hash
    double C, w0, R_min, t;
    vector<RStarTreeIndex<K>> indices;  // L R*-trees de K dimensiones
    vector<vector<double>> datos;       // Datos originales D-dim
    vector<vector<vector<double>>> a;   // Proyecciones LÃ—KÃ—D
    
public:
    DBLSH(int dim, int L, double C, double R_min, double t, unsigned seed);
    void insertar(const vector<vector<double>>& datos);
    
    // Algorithm 1
    vector<tuple<int, vector<double>, double>> 
        RC_NN_K(query, r, c, k, T);
    
    // Algorithm 2  
    vector<tuple<int, vector<double>, double>> 
        C_ANN_K(query, c, k);
    
    // Ground truth (fuerza bruta)
    vector<pair<int, double>> 
        encontrarKVecinosReales(query, k);
};
```

### ProyecciÃ³n LSH

```cpp
// Hash functions gaussianas N(0,1)
for (i = 0; i < L; i++)
    for (j = 0; j < K; j++)
        for (d = 0; d < D; d++)
            a[i][j][d] ~ N(0,1)

// Proyectar punto D-dim â†’ K-dim
hash_result[j] = Î£(a[tabla][j][d] * punto[d]) for d in [0..D-1]
```

### R*-tree Bulk-Loading

```cpp
// Construir Ã­ndice eficientemente
for (tabla = 0; tabla < L; tabla++) {
    proyecciones = [];
    for (punto in datos) {
        hash = funcionHash(punto, tabla);  // D â†’ K dimensiones
        proyecciones.push_back({hash, id});
    }
    indices[tabla].bulkLoad(proyecciones);  // ConstrucciÃ³n bottom-up
}
```



---

## ğŸ”§ Troubleshooting

### Problemas Comunes

**Error: `No se pudo abrir fashion_mnist.csv`**
```bash
# Verificar que el archivo existe en el directorio raÃ­z
ls -lh fashion_mnist.csv
```

**CompilaciÃ³n falla con error de Boost**
```bash
# Instalar Boost en Ubuntu/Debian
sudo apt-get install libboost-all-dev

# Verificar versiÃ³n (requiere 1.70+)
dpkg -l | grep libboost
```

**Resultados con recall 0% o muy bajo**
- Verificar parÃ¡metros: C, t, K, L deben ser apropiados para el dataset
- Probar con `calculate_parameters.py` para encontrar configuraciÃ³n Ã³ptima
- El recall bajo puede indicar que `t` es muy pequeÃ±o o `C` muy estricto

**Tiempo de ejecuciÃ³n muy largo**
- Reducir el tamaÃ±o del dataset en `loadDataset()`
- Ajustar parÃ¡metros: reducir `L` o `t`
- Compilar con optimizaciones: `make clean && make all`

**Memoria insuficiente**
```bash
# Reducir dataset en main_k.cpp o main_grafico.cpp
# Cambiar: loadDataset("fashion_mnist.csv", 60000)
# Por:     loadDataset("fashion_mnist.csv", 30000)
```

---

## ğŸ“š DocumentaciÃ³n Complementaria

### Archivos Importantes

1. **CÃ³digo fuente principal**
   - `R_star2.h`: ImplementaciÃ³n del Ã­ndice R*-tree
   - `main_k.cpp`: Experimento k-NN con parÃ¡metros optimizados
   - `main_grafico.cpp`: Experimento varying n del paper
   - `main.cpp`: Testing con dataset sintÃ©tico

2. **Comentarios en cÃ³digo**
   - Headers explicativos en main_k.cpp y main_grafico.cpp
   - DocumentaciÃ³n inline de algoritmos
   - Referencias a ecuaciones del paper (Eq. 11, 12)

3. **Resultados experimentales**
   - `results/knn_results.csv`: k, recall, ratio
   - `results/varying_n_results.csv`: n, recall, ratio, time

4. **Scripts de utilidad**
   - `calculate_parameters.py`: OptimizaciÃ³n de parÃ¡metros C, t, K, L
   - `pgm_to_png.py`: ConversiÃ³n de imÃ¡genes PGM a PNG

---

## ğŸ› ï¸ Comandos Make

```bash
# Compilar todos
make all

# Ejecutables individuales
make main_k          # k-NN benchmark
make main_grafico    # Varying n
make main2           # Testing sintÃ©tico

# Ejecutar
make run-k           # k-NN experiments
make run-grafico     # Varying n experiments
make run-test        # main2 (dataset sintÃ©tico)

# Utilidades
make clean           # Limpiar binarios
make rebuild         # Limpiar y recompilar
```

---

## ğŸ“– Referencias

### Paper Original

- **TÃ­tulo:** DB-LSH: Locality-Sensitive Hashing with Query-based Dynamic Bucketing
- **Autores:** Yao Tian, Xi Zhao, Xiaofang Zhou
- **Conferencia:** IEEE ICDE 2022
- **DOI:** 10.1109/ICDE53745.2022.00264
- **GitHub:** https://github.com/Jacyhust/DB-LSH

### Dataset

- **Fashion-MNIST** by Zalando Research
- **TamaÃ±o:** 60,000 training images + 10,000 test
- **Formato:** 28Ã—28 grayscale (784 features)
- **Clases:** 10 (T-shirt, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot)

### TecnologÃ­as

- **C++17:** std::filesystem, structured bindings, templates
- **Boost 1.70+:** Boost.Geometry R*-tree
- **Python 3:** pandas, matplotlib, numpy


---

## ğŸ‘¨â€ğŸ’» Autores

**Silva Anampa, Manuel Jesus**  
**Campoverde San MartÃ­n, Yacira Nicol**  
**Bracamonte Toguchi, Mikel Dan**  
**Garcia Calle, Renato**  
Proyecto de Estructuras de Datos Avanzadas  
Curso: EDA  
Fecha: Noviembre 2024

---
